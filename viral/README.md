# Viral Marketing Simulator & Fake News Detector

> "넷플릭스 추천 알고리즘을 뒤집으면 바이럴 확산을 예측할 수 있지 않을까?"

## 어떻게 시작됐나

배달 플랫폼 시뮬레이터(`reaction_diffusion_grid.py`)를 만들고 있었다.
주문 밀도와 라이더 밀도가 격자 위에서 반응-확산 방정식으로 움직이는 모델.

그러다 문득 떠올랐다:

> **격자 라플라시안을 소셜 그래프 라플라시안으로 바꾸면?**

- 배달: `u` = 주문 밀도, `L` = 격자 라플라시안
- 바이럴: `u` = 콘텐츠 감염률, `L` = 소셜 그래프 + 코사인 유사도

수학적으로 완전히 같은 구조다. 라플라시안만 교체하면 된다.

## 핵심 아이디어

넷플릭스는 **"비슷한 유저가 본 콘텐츠"**를 추천한다 (코사인 유사도).
이걸 뒤집으면 **"콘텐츠를 좋아한 유저와 비슷한 유저"**로 확산 경로를 예측할 수 있다.

```
∂u/∂t = L_cos @ u

u     = 각 유저의 "감염" 확률 벡터
L_cos = 코사인 유사도 가중 그래프 라플라시안
```

여기서 한 단계 더:

> **진짜 뉴스와 가짜 뉴스는 확산 패턴이 다르지 않을까?**

- 진짜 뉴스: 유사한 관심사를 가진 유저끼리 퍼짐 (동질적 전파)
- 가짜 뉴스: 관심사 상관없이 무차별적으로 퍼짐 (이질적 전파)

이 차이가 **라플라시안 고유값 스펙트럼**에 나타날 것이다.

## 실험 결과: 가설이 맞았다

McIntire 데이터셋(Real 200건 + Fake 200건)과 BBC/NPR RSS 실시간 뉴스 60건으로 검증했다.

### 코사인 유사도 히트맵

| Real News | Fake News | RSS Hot News |
|:---------:|:---------:|:------------:|
| 블록 대각선 구조 (주제 클러스터) | 균일하게 낮음 (구조 없음) | 이슈별 클러스터 존재 |

### 수치 비교

| Metric | Real News | Fake News |
|--------|-----------|-----------|
| Mean Cosine Similarity | **0.0522** | 0.0345 |
| Fiedler λ₂ | **~0** (disconnected clusters) | 0.307 |
| Eigenvalue Max | **18.58** | 12.07 |

**해석:**
- Real 뉴스의 Fiedler λ₂ ≈ 0 = 그래프가 끊어진다 = **주제별로 완전히 분리된 클러스터**
- Fake 뉴스의 Fiedler λ₂ = 0.307 = 연결된 그래프 = **주제 경계 없이 섞여 있음**
- Real 뉴스의 평균 코사인 유사도가 1.5배 높음 = **같은 주제 기사끼리 더 비슷**

이건 시뮬레이터의 예측과 정확히 일치한다.

## 그러면 확산을 멈출 수 있나?

가설이 맞다면 다음 질문은 자연스럽다: **가짜뉴스 확산을 중간에 정지시킬 수 있는가?**

100노드 소셜 그래프에서 4가지 차단 전략을 시뮬레이션했다.

### 차단 전략 비교 (100노드, 가짜뉴스 95개 노드 감염 기준)

| 전략 | 감염 노드 | 감소율 | 비용 |
|------|-----------|--------|------|
| 아무것도 안 함 | 95 | — | — |
| **허브 5개 사전 제거** | 33 | **-65%** | 5 nodes |
| 저유사도 엣지 차단 | 56 | -41% | threshold 설정 |
| **조기 탐지 + 허브 차단** | 4 | **-96%** | 5 nodes (지연) |
| 랜덤 5개 제거 (기준선) | 85 | -10% | 5 nodes |

### 핵심 발견

**1. 조기 탐지가 가능하다**
- 전체 시간의 **0.9% 시점**(t=0.028)에서 이미 Normal vs Fake의 확산 패턴이 갈린다
- 감염 노드의 표준편차 추이만 보면 초기에 구분 가능

**2. 허브를 막아야 한다**
- 랜덤 5개 제거 = **10% 감소** (거의 효과 없음)
- 허브 5개 제거 = **65% 감소** (같은 비용, 6.5배 효과)
- "아무나 막으면 안 되고, 정확히 허브를 막아야 한다"

**3. 조기 탐지 + 허브 차단 = 사실상 확산 정지**
- 감염 15% 도달 시점에서 허브 5개만 차단하면 **96% 감소**
- 95개 → 4개. 사실상 멈춘다.

**4. 전파 경로의 유사도가 다르다**
- Normal 전파 엣지 평균 유사도: **0.601**
- Fake 전파 엣지 평균 유사도: **0.559**
- 가짜뉴스는 유사도가 낮은 엣지로도 전파됨 → 이질적 확산의 증거

### 이게 왜 가능한가

```
가짜뉴스 확산 감지:
    1. 확산 초기 패턴 모니터링 (std dev 추이)
    2. 정상 확산 대비 이상 패턴 감지 (t=0.028, 전체의 0.9%)
    3. 고유벡터 중심성 top-k 노드 즉시 차단
    4. 확산 96% 감소
```

소셜 그래프의 구조(scale-free)가 약점이자 방어 포인트다.
허브가 있어서 빨리 퍼지지만, 바로 그 허브를 막으면 네트워크가 분절된다.

## 구조

```
viral/
├── README.md                    # 이 문서
├── LICENSE                      # MIT License
├── viral_marketing_memo.md      # 최초 아이디어 메모
├── traffic_signal_memo.md       # 신호등 제어 메모 (다음 프로젝트)
│
├── reaction_diffusion_grid.py   # 원본: 배달 플랫폼 반응-확산 시뮬레이터
├── viral_marketing_sim.py       # 소셜 그래프 확산 시뮬레이터
├── viral_marketing_demo.html    # 웹 인터랙티브 데모
├── news_data_collector.py       # 실제 뉴스 데이터 수집 & 분석
├── diffusion_intervention.py    # 차단 전략 시뮬레이션 & 검증
│
├── data/
│   ├── mcintire_news.json       # Real/Fake 뉴스 데이터 (캐시)
│   └── analysis_summary.json    # 분석 수치 요약
│
└── output/
    ├── viral_marketing_analysis.png       # 시뮬레이터 6-panel
    ├── news_cosine_spectral_analysis.png  # 실데이터 스펙트럼 분석
    ├── intervention_analysis.png          # 차단 전략 분석 8-panel
    ├── snapshots_normal_content.png       # 정상 확산 스냅샷
    └── snapshots_fake_news.png            # 가짜 확산 스냅샷
```

## 실행 방법

### Python 시뮬레이터
```bash
pip install numpy matplotlib scipy
python viral_marketing_sim.py
# → output/ 에 시각화 이미지 생성
```

### 웹 데모
`viral_marketing_demo.html`을 브라우저에서 열면 바로 동작한다.
- 노드 클릭 → 시드 유저 설정
- Normal / Fake News 모드 토글
- 슬라이더로 파라미터 조절

### 데이터 수집 & 분석
```bash
pip install numpy matplotlib scikit-learn requests feedparser
python news_data_collector.py
# → GitHub에서 라벨링 데이터셋 다운로드
# → BBC/NPR RSS에서 실시간 뉴스 수집
# → TF-IDF 코사인 유사도 스펙트럼 분석
# → output/ 에 결과 이미지 생성
```

### 차단 전략 시뮬레이션
```bash
python diffusion_intervention.py
# → 6가지 차단 전략 비교 시뮬레이션
# → 조기 탐지 시점 분석
# → output/intervention_analysis.png 생성
```

## 알고리즘 상세

### 1. Barabasi-Albert 그래프
Power-law degree distribution을 가진 scale-free 네트워크.
소셜 네트워크의 "소수의 허브가 대부분의 연결을 가진다"는 특성을 재현.

### 2. 코사인 유사도 라플라시안
```
A_cos_ij = cosine_similarity(user_i, user_j)  (엣지가 있는 경우)
L = D - A_cos                                  (D = degree matrix)
```
[-1, 1] 유사도를 [0, 1]로 선형 변환하여 모든 엣지에 양수 가중치 보장.

### 3. 확산 (Forward Euler)
```
u(t + dt) = u(t) - dt * coeff * L @ u(t)
```
라플라시안 확산: 높은 곳에서 낮은 곳으로 흐른다. 총량은 보존.

### 4. 인플루언서 선정
A_cos의 최대 고유벡터 = 고유벡터 중심성.
이 값이 큰 노드가 확산 효율이 가장 높은 시드 유저.

### 5. 가짜뉴스 판별
정상: 코사인 유사도 가중 라플라시안 → 유사한 유저끼리 확산
가짜: 무가중 라플라시안 → 무차별 확산
→ **고유값 스펙트럼 분포의 차이**로 구분 가능

## Limitations

- **스케일**: 100노드 BA 그래프 ≠ 수억 노드 실제 소셜 네트워크. 허브 차단 96%가 그대로 스케일될 리는 없다.
- **확산 모델**: Forward Euler 라플라시안 확산은 실제 리트윗 캐스케이드, 알고리즘 추천 증폭 등을 반영하지 못한다.
- **가짜뉴스 = 무가중 라플라시안**: 극단적 가정. 실제 가짜뉴스도 어느 정도는 관심사 기반으로 퍼진다. 현실은 유사도 가중과 무가중 사이 어딘가.
- **데이터**: McIntire 데이터셋은 2016년 미국 선거 기사 중심. 시대/언어/플랫폼별 편향 존재.
- **TF-IDF**: 의미 유사도가 아닌 단어 빈도 기반. 임베딩(BERT 등)으로 바꾸면 결과가 달라질 수 있다.

그래도 **방향성과 메커니즘**은 유효하다고 본다. 코사인 유사도 구조 차이는 실데이터에서 나온 거고, scale-free 네트워크의 허브 취약성은 이미 검증된 성질이니까.

## 흐름 요약

```
배달 시뮬레이터 (격자 PDE)
    ↓ 라플라시안 교체
바이럴 확산 시뮬레이터 (소셜 그래프)
    ↓ 가설: 확산 패턴이 다를 것
실제 뉴스 데이터로 검증
    ↓ 결과: 코사인 유사도 구조가 다름
가짜뉴스 탐지 가능성 확인
    ↓ 차단할 수 있는가?
차단 전략 시뮬레이션
    ↓ 결과: 허브 5개 차단으로 96% 감소
조기 탐지 + 허브 차단 = 확산 정지
```
