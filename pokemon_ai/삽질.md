# Pokemon Battle AI 개발일지

> 나흘간의 삽질 기록.
> 딥러닝으로 시작해서 게임이론 엔진으로 끝난 여정. 나중에 또 건들 거 같지만 일단.
>
> AI가 어떤 로직으로 돌아가는지 나흘 동안 너무 많이 흡수했다.
> 각 게임에서 지배 전략이 뭔지, 필요한 툴은 무엇인지. 알아간 게 너무 많다.
>
> 오히려 AI에 대한 공포가 사라졌다.
> 신경망한테 데미지 공식을 "학습"시키려 했더니 쓰레기가 나왔다.
> 공식을 직접 짜주니까 83%, 매크로 전략을 직접 설계해주니까 인간한테 6:4.
> 결국 얘네 인간 데이터 없이 아무것도 못한다.
> AlphaGo도 인간 기보 16만 판으로 시작했고, LLM도 인류의 텍스트를 전부 먹고 돌아간다.

---

## Day 1: "딥러닝이면 다 되겠지"

### 시도 1: 신경망 평가함수 (neural_net.py)

처음 접근은 단순했다. 배틀 상태(HP, 타입, 능력치 등)를 벡터로 만들어서
MLP에 넣으면 "누가 이기고 있는지" 학습할 거라고 생각했다.

학습 데이터는 Pokemon Showdown 리플레이를 `replay_crawler.py`로 수천 판 크롤링,
`replay_analyzer.py`로 파싱해서 (상태, 승패) 쌍을 만들었다.

**결과: 쓰레기.**

신경망은 포켓몬 메카닉을 전혀 이해하지 못했다.
- Ho-Oh가 풀피에 Recover가 있으면? 네트워크: "+0.999 이기고 있음!" → 실제: 회복 무한루프에 빠져서 영원히 안 끝남
- 상대가 확정 1타로 죽이는 상황에서도 HP가 높다는 이유로 "+0.8" 찍음
- 타입 상성? STAB? 그런 건 학습 데이터에서 패턴으로 추출하기엔 너무 복잡

근본적 문제: 포켓몬 데미지 공식은 **명시적**이다. (공격×위력×상성×STAB×...) / 방어
이걸 "학습"할 필요가 없다. 그냥 계산하면 된다.

### 시도 2: MCTS (Monte Carlo Tree Search)

AlphaZero가 바둑을 깼으니까 MCTS면 되지 않을까?
`mcts.py`를 구현하고 돌려봤다.

**문제 1: 동시 행동 게임**
- 체스/바둑: 내가 두고 → 상대가 둔다 (순차적)
- 포켓몬: 양쪽이 **동시에** 선택하고 → 결과가 나온다
- MCTS는 순차 게임 전제. 포켓몬에 근본적으로 맞지 않는 알고리즘

**문제 2: 랜덤 롤아웃의 무의미**
- MCTS는 끝까지 랜덤으로 플레이해서 승패를 추정하는데
- 포켓몬에서 랜덤 플레이 = 아무 의미 없는 행동의 연속
- "랜덤으로 100번 굴렸더니 60번 이겼다" → 실제 플레이와 무관

### 깨달음: "포켓몬은 바둑이 아니라 체스다"

여기서 핵심 전환점이 왔다.

- **바둑**: 규칙은 단순하지만 패턴이 창발적 → 신경망이 필요
- **체스**: 말의 가치가 계산 가능 → 룰 기반 평가 + 탐색
- **포켓몬**: 데미지 공식, 타입 차트, 특성, 아이템 전부 **데이터베이스에 있음**

신경망으로 "배워야" 할 것이 없다. 전부 계산하면 된다.
Stockfish가 체스를 신경망 없이 이기듯, 포켓몬도 룰 기반으로 간다.

---

## Day 1.5: Nash 균형의 발견

### 동시 행동 문제를 어떻게 풀 것인가

체스의 minimax는 "내가 최선을 두면 상대도 최선을 둔다"를 가정한다.
근데 포켓몬은 **동시에** 행동을 선택한다. 내가 교체할지 공격할지를 정할 때
상대가 뭘 할지 모른다.

이건 **영합 행렬 게임(zero-sum matrix game)**이다.

가위바위보를 생각하면 된다:
- 가위를 무조건 내면? → 상대가 바위만 내서 진다
- 최적 전략: 가위 1/3, 바위 1/3, 보 1/3 → **혼합 전략(mixed strategy)**
- 이게 바로 **Nash 균형**

### 보상행렬(Payoff Matrix) 시스템 구축

1. 양쪽의 합법 행동을 전부 열거 (기술 4개 + 교체 2~5개 + 테라 변형)
2. 모든 (내 행동 × 상대 행동) 조합을 시뮬레이션
3. 각 결과 상태를 평가 → N×M 보상행렬 완성
4. 선형계획법(LP)으로 Nash 균형 풀기
5. 출력: 각 행동의 확률 분포 ("불대문자 60%, 교체→글라이온 30%, 용의춤 10%")

`nash_solver.py` + `endgame_solver.py` 구현.

### 첫 동작 버전
- depth-1 (1턴만 내다봄)으로 랜덤 상대에 **승률 ~70%**
- 되긴 되는데 1턴밖에 안 보니까 함정에 빠짐
- "지금 때리면 이득이지만 다음 턴에 죽는다" 같은 걸 못 봄

---

## Day 2: 룰 기반 평가함수 v1 (83%)

### Stockfish 스타일 평가

`rule_evaluator.py` — 배틀 상태를 받아서 "누가 유리한가"를 [-1, +1]로 출력.
10개 컴포넌트의 가중합에 tanh를 씌운다.

| # | 컴포넌트 | 가중치 | 설명 |
|---|---------|--------|------|
| 1 | 머테리얼 | 1.2 | 생존 포켓몬 수 차이 (3v2면 +1.2) |
| 2 | HP 경제 | 0.6 | 총 HP% 비교 |
| 3 | 액티브 매치업 | 0.5 | 현재 1v1 유불리 |
| 4 | 스윕 위협 | 1.5 | 랭크업한 에이스가 상대를 쓸 수 있는가 |
| 5 | 카운터 유무 | 0.8 | 상대 위협에 대한 답이 있는가 |
| 6 | 헤저드 | 0.3 | 스텔스락/압정/독압정 |
| 7 | 상태이상 | 0.4 | 화상/마비/독 어드밴티지 |
| 8 | 랭크업 | 0.6 | 능력치 변화 가치 |
| 9 | 필드 | 0.3 | 날씨/필드/벽/순풍 |
| 10 | 테라 자원 | 0.15 | 테라스탈 사용 가능 여부 |

### 데미지 계산기

`damage_calc.py` — 9세대 데미지 공식 완전 구현.
STAB, 타입 상성, 특성, 아이템, 날씨, 필드, 화상, 급소...
Pokemon Showdown 데미지 계산기와 반올림 수준까지 일치.

**결과: 승률 83%**. 드디어 의미 있는 수치가 나왔다.

---

## Day 2: 프루닝 재앙 (83% → 60%)

### "당연히 안 쓸 기술은 빼면 빨라지겠지"

탐색 속도를 올리려고 "당연히 나쁜" 수를 미리 잘라냈다:
- 상대가 면역인 기술 (노말 → 고스트)
- 이미 상태이상 걸린 상대에 또 상태이상
- 풀피에서 회복기
- +6에서 또 랭크업

**결과: 승률 60%로 폭락.** 83%에서 23%p 하락.

### 왜 프루닝이 모든 걸 망쳤나

이게 이 프로젝트에서 가장 중요한 교훈이다.

**Nash 균형은 모든 선택지가 있어야 성립한다.**

예를 들어:
- 내가 불꽃 기술을 가지고 있으면 → 상대는 물 타입 교체를 "고려"해야 함
- 그 불꽃 기술을 "상성이 안 좋으니까" 프루닝하면?
- → 상대는 물 타입 교체를 고려할 필요 없음
- → 상대의 Nash 전략이 완전히 바뀜
- → 내 최적 대응도 바뀜
- → 결과: 완전히 다른 게임이 됨

보상행렬에서 한 행이나 한 열을 빼면 Nash 균형 자체가 달라진다.
이건 체스의 alpha-beta 프루닝과 근본적으로 다르다.
체스는 순차 게임이라 "이 수보다 확실히 나쁜 수"를 안전하게 잘라낼 수 있지만,
동시 행동 게임에서는 "나쁜 수"가 상대의 전략을 제약하는 역할을 한다.

**가위바위보에서 가위를 "약하니까" 빼면? 바위만 내게 되고, 상대는 보만 내서 진다.**

### 안전한 프루닝: 딱 3가지만

고통스러운 실험 끝에 안전한 프루닝은 이것뿐:
1. 풀피에서 회복기 (물리적으로 효과 없음)
2. 최대치 헤저드에서 또 헤저드 (불가능한 행동)
3. +6에서 또 랭크업 (불가능한 행동)

**"나쁜 행동"이 아니라 "불가능한 행동"만 잘라야 한다.**

---

## Day 2.5: 평가함수 v2 (93%)

### 승률 83%의 패배 분석

17판의 패배를 분석하니 패턴이 보였다:
- Ho-Oh가 Recover로 무한 회복 → 우리 팀 전체가 못 잡음
- Gliscor + Ho-Oh 사이클 → 교대하면서 영원히 안 죽음
- 물리벽 + 특수벽 조합 → 어떤 공격이든 받아냄

공통점: **회복하거나 사이클 도는 상대를 못 뚫음**

### 컴포넌트 11: 돌파 가능성 (Breakthrough) — 가중치 1.0

상대 팀에 회복기 보유자가 있으면:
- 우리 팀 전체에서 그 벽한테 넣을 수 있는 최대 데미지 계산
- 최대 데미지 < 회복량(HP의 50%)이면 → "이놈 못 잡음" 감점
- 도발(Taunt)/트릭(Trick)/맹독(Toxic) 같은 anti-stall 도구 있으면 → 감점 경감
- 천진(Unaware) 특성이면 → 부스트 무시하고 재계산

### 컴포넌트 12: 방어 코어 — 가중치 0.7

상대에 물리벽 + 특수벽이 동시 생존하면:
- 사이클 성립 가능 → 감점
- 둘 다 회복기 보유 → 추가 감점
- 하나 잡으면 사이클 붕괴 → 페널티 해제

**결과: 승률 93%** (+10%p). 회복 사이클에 대한 인식이 핵심이었다.

---

## Day 3 시작: 리플레이 분석 — "모든 조합을 찾을 이유가 없었다"

되게 당연한 얘기였다.

처음엔 6C3 × 3 = 60의 모든 조합을 탐색해야 한다고 생각했다.
근데 나도 게임을 할 때, 상대 상성에 맞춰서 포켓몬을 고르긴 하는데,
시너지가 나도록 조합을 강제한다.

리플레이 분석에서도 명확했다.
고레이팅 플레이어들의 선출 패턴을 보면 — 브레이커+클리너, 세터+스위퍼, 앵커+피벗.
**역할 조합이 강제되어 있다.** 랜덤 3마리를 뽑는 사람은 없다.

모든 조합을 찾을 이유가 없었다. 시너지 있는 조합만 보면 된다.

---

## Day 3: 스마트 선출 (Smart Team Selection)

### 문제 인식

각 팀은 6마리인데 3마리만 배틀에 나간다. C(6,3) = 20가지 조합.
지금까지는 **랜덤 3마리**를 내보내고 있었다.
"아무거나 3마리 골라도 잘 싸우면 되지 않나?" → 아니다.

에이스 3마리를 잘 골라도 상대 구성에 안 맞으면 의미 없고,
시너지가 맞는 3마리가 화력이 부족해도 안 되고,
스위퍼가 없으면 마무리를 못 짓는다.

### 선출 알고리즘: 5개 평가 컴포넌트

20개 조합을 전부 평가해서 최적을 고른다:

| 컴포넌트 | 가중치 | 로직 |
|---------|--------|------|
| 위협 커버리지 | 2.0 | 상대 6마리 전부에 효과적 타격 가능한가 |
| 킬 압력 | 1.5 | 상대 몇 마리를 확2 이내로 잡을 수 있는가 |
| 스윕 잠재력 | 1.0 | 용춤/나비춤 + 고속 스위퍼가 있는가 |
| 방어 시너지 | 1.0 | 타입 분산 — 약점을 서로 커버하는가 |
| 속도 밸런스 | 0.5 | 빠른 놈 + 느린 놈 섞여있는가 |

~35ms 만에 20개 조합 전부 평가. 오버헤드 거의 없음.

### 리드(선발) 선택

3마리를 골랐으면, 누구를 첫 번째로 내보낼지도 중요하다.

포켓몬 배틀에서 "선발로 설계된" 포켓몬이 있다:
- **필드 세팅**: 스텔스락, 압정, 독압정 → **+2.0**
- **선발 무브**: 속이다(Fake Out), 도발(Taunt), 앵콜(Encore) → **+1.5**
- **피벗**: 유턴, 볼트체인지, 플립턴 → **+1.0**
- **기합의 띠**: 확1 방지 → **+0.8**
- **고속**: 130족 이상 +0.5, 100족 이상 +0.2
- **적성 설정 스위퍼**: 용춤, 칼춤 등 → **-1.5** (후반에 내보낼 것)
- **회복 탱커**: 회복기 보유 → **-0.5** (선발로 낭비하지 말 것)

여기에 **OHKO 매치업 체크** 추가:
- 상대 6마리 중 내가 확1로 잡을 수 있는 비율 → **+1.0**
- 상대 6마리 중 내가 확1로 죽는 비율 → **-1.5** (비대칭 — 죽는 게 더 나쁨)

이 점수가 가장 높은 포켓몬이 선발(인덱스 0)로 나간다.

---

## Day 3: 테라스탈 1턴차 낭비 문제

### 패턴 발견

스마트 선출 적용 후 돌렸는데, 패배한 3판을 분석하니:

```
G13: T0 Tera+Ice Shard (미미큐 상대) → Tera 낭비, 이후 Tera 없어서 패배
G26: T0 Tera+Earthquake (약간의 추가 데미지) → 결정적 순간에 Tera 없음
G34: T0 Tera+Close Combat → 같은 패턴
```

**3판 전부 첫 턴에 테라를 쓰고, 나중에 필요할 때 없어서 짐.**

### 분석

테라스탈 자원 가중치가 0.15였다. AI 입장에서:
- "지금 테라 쓰면 데미지 1.3배 → 이득 +0.3"
- "테라 자원 잃음 → 손해 -0.15"
- 차이 +0.15 → "쓰는 게 이득!"

근데 실제로 테라는:
- 에이스한테 몰아줘야 스윕 가능
- 타입 상성 역전으로 기점을 잡는 결정적 도구
- 1턴차에 쓰면 나중에 진짜 필요할 때 없음

**수정: 테라 가중치 0.15 → 0.6**

이제 테라를 쓰려면 최소 0.6 이상의 전술적 이득이 있어야 함.
결정적 순간(확정 킬, 타입 역전)에만 사용하게 됨.

---

## Day 3: 테라 STAB 버그 (가장 고통스러운 발견)

### 증상

코라이돈 (격투/드래곤, 테라: 불꽃)이 글라이온 상대로 테라+인파이터를 사용.
글라이온은 땅 타입이라 **지진**이 있는데, 테라 불꽃이면 **지진에 2배**로 약해진다.
AI는 이걸 "좋은 수"라고 판단했다. 왜?

### 원인 추적

직접 대전하면서 발견: "코라이돈은 격투/드래곤이고 테라가 불... 그러면 글라이온이 100퍼 지진이 있을텐데 그건 손해야"

코드를 보니:

```python
# _calc_damage_fast, 라인 1141
original_types = attacker.types
```

**문제: 테라 후 attacker.types는 이미 [tera_type]으로 바뀌어 있다!**

그래서:
- `original_types = ["Fire"]` (실제로는 ["Fighting", "Dragon"]이어야 함)
- 불꽃 기술: 테라타입 + "원래타입" 둘 다 일치 → STAB 2.0x (실제: 1.5x)
- 격투 기술: 원래타입에 없음 → STAB 1.0x (실제: 1.5x)
- 드래곤 기술: 원래타입에 없음 → STAB 1.0x (실제: 1.5x)

**불꽃 기술 데미지는 과대평가, 격투/드래곤 기술은 과소평가.**
이래서 AI가 테라를 쓰면 "불꽃이 엄청 강해진다!"고 착각하고 아무 데나 테라를 쓴 거다.

### 수정

```python
if attacker.is_tera:
    dex = self.gd.get_pokemon(attacker.species_id)
    original_types = dex.get("types", attacker.types) if dex else attacker.types
else:
    original_types = attacker.types
```

시뮬레이터가 하는 것처럼 **도감(dex) 데이터에서 원래 타입**을 가져온다.

### 임팩트

수정 후 테라 사용 패턴이 완전히 바뀌었다.
- 수정 전: 1턴차에 무의미한 테라 남발
- 수정 후: 결정적 순간에만 사용, 자원 보존
- 이 버그 하나가 depth 1~8 전체 리프 노드에 전파되고 있었다

참고로 이 버그를 찾는 과정에서 나(AI)는 "코라이돈은 격투/불꽃"이라고 잘못 말했고,
코라이돈은 격투/드래곤이고 테라가 불인데, 그걸 AI가 잘못 계산하고 있었다.
강철/불이면 격투 두배라는 타입 상성도 실전에서 틀린 걸 잡았다.
**포켓몬 지식이 없으면 버그 찾기도 불가능했다.**

---

## Day 3: depth 진실 — "깊이가 문제가 아니라 프루닝이 문제였다"

### 이전의 잘못된 결론

Day 2에서 depth-3 + 공격적 프루닝을 같이 시도했다가 실패.
그때 결론: "depth-3은 너무 깊다. 가중치가 깨진다."

**이 결론이 틀렸다.**

### 뒤늦은 깨달음

"아까 depth 올려서 가중치 문제 생긴건 프루닝 때문 아니였음?"

맞았다. depth 증가와 공격적 프루닝을 **동시에** 적용해서 뭐가 문제인지 구분을 못 했다.
안전 프루닝 + depth 증가를 **따로** 테스트한 적이 없었다.

### depth-4 + 안전 프루닝만

**결과: 48연승 후 첫 패배.**

- depth-2: 93%
- depth-4: 96%+
- depth-3 + 공격 프루닝: 60% (프루닝이 원인이었지, 깊이가 아니었다)

4턴 = 방어 사이클 한 바퀴. 회복기 → 공격 → 회복기 → 공격.
이 사이클을 **통째로** 볼 수 있게 되니까 "회복해봤자 결국 죽는다"를 알게 됨.

> "결국 사흘의 삽질이 의미가 없던 게 아니였어. '불가능을 제외하고 남은 것이 진실이다.'"

---

## Day 3: 패배 분석 — 전부 사이클

### 100판 결과: 94승 6패 (승률 94%)

패배 6판 전수 분석:

**G44: Dondozo Curse+Rest 사이클**
- Dondozo가 저주(Curse)로 공방 올리고 잠자기(Rest)로 풀회복
- 우리 팀 전체가 Dondozo를 2타 이내로 못 잡음
- Fissure(일격기) 시도 → 빗나감 → 게임 오버

**G51: Ho-Oh 내구 + Raging Bolt Thunderclap(선제기)**
- Raging Bolt가 매턴 Thunderclap으로 먼저 때림
- HP 소모전에서 밀림 + Ho-Oh가 뒤에서 대기
- 화력 부족으로 Ho-Oh 207HP를 뚫을 수 없음

**G52: Ho-Oh Recover 사이클 (가장 심각한 패배)**
- Dragonite가 Scale Shot + Dragon Dance로 스윕 세팅 성공
- **GV +0.957까지 올라감** — AI는 "거의 이겼다"고 판단
- 그런데 Zamazenta가 **Iron Defense를 2회 사용** (턴 낭비!)
- Ho-Oh가 **Recover로 풀회복**, Sacred Fire로 화상 걸림
- GV +0.98에서 -0.32로 역전. **평가가 현실과 동떨어져 있었다**
- 핵심: 랭크업을 아무리 올려도 Ho-Oh Recover > 최대 데미지면 영원히 못 잡음

**G84: 미러 매치 — 순수 운**
- 상대 랜덤 행동이 우연히 최적에 가까웠음
- Dragonite 1v1에서 HP 100 vs 166. 구조적 문제 아님

**G85: Ho-Oh Recover + Tera+Brave Bird**
- Calyrex-Shadow가 Ho-Oh한테 2턴 만에 죽음
- Ho-Oh가 Recover하면서 Tera+Brave Bird로 공격
- 또 Ho-Oh 사이클

**G94: Flutter Mane/Iron Moth 교체 사이클 (새로운 유형)**
- Dragonite **+3 공격/스피드** 완벽 세팅 → GV +0.994
- 상대 Flutter Mane과 Iron Moth가 **번갈아 교체**하면서 타격 분산
- +3 Dragonite가 **공격 한 번도 제대로 못 꽂고 소모됨**
- Encore/Taunt 같은 보조기 사용하다가 시간 낭비
- GV +0.994에서 역전 — **"부스트 = 이김"이라는 평가가 틀렸다**

### 패턴

| 게임 | 패인 유형 |
|------|----------|
| G44 | 회복 사이클 (Curse+Rest) |
| G51 | 회복 + 선제기 사이클 |
| G52 | 회복 사이클 (Recover) + 평가 오류 |
| G84 | 운 |
| G85 | 회복 사이클 (Recover + Tera) |
| G94 | 교체 사이클 (회복기 없이 교대만으로) |

**6판 중 5판이 사이클.** 이거 하나가 남은 문제의 전부.

---

## Day 3: "사이클이 게임프리크가 너프하는 이유"

여기서 핵심 통찰이 왔다:

포켓몬에서 사이클이 생각보다 강력한 수법이라는 거,
왜 자꾸 너프하는지가 여기서 딱 나온다. 뚫기 어려운 전술이다.

depth-8까지 최적 수를 탐색하는 엔진이 **수학적으로 사이클을 못 뚫는다**면,
그 전술이 진짜 강력하다는 뜻이다.

게임프리크가 매 세대 사이클을 너프하는 이유:
- 넉오프(Knock Off) 강화 → 아이템 떨궈서 내구 깎기
- 테라스탈 → 타입 바꿔서 사이클 깨기
- 화력 인플레 → 확2가 확1이 되면 사이클 불가
- 유턴/볼트체인지 → 사이클 중 주도권 탈취

**"사이클이 뚫리지 않는 게임 = 재미없는 게임"**이라 뚫는 도구를 계속 추가하지만,
잘 짜인 사이클은 여전히 최강 전술.

4~5세대 때 가장 강력했던 건 모래바람파티, 비파티.
특화된 포켓몬으로 특성이랑 타입 살려서 사이클 극대화. 그리고 딜러 한두명.

---

## Day 3: 돌파 패널티 v2 — 벽 중요도 스케일링

### 기존 문제

못 뚫는 벽 하나당 **고정 0.5 감점**, 최대 1.0.

G52에서: 3v1 (Ho-Oh만 남음)
- 머테리얼: +2.4 (포켓몬 2마리 우세)
- 돌파 실패: -0.5
- 합계: +1.9 → tanh(+1.9) = **+0.96**
- AI: "이기고 있다!" → Iron Defense 세팅 → **Ho-Oh가 회복하면서 역전**

### 수정: 상대 남은 수에 반비례

| 상대 남은 수 | 벽 패널티 | 논리 |
|-------------|----------|------|
| 3마리 중 1벽 | 0.5 | 나머지 먼저 잡으면 됨 |
| 2마리 중 1벽 | 1.0 | 절반이 벽 = 심각 |
| 1마리 = 벽 | 2.0 | **이놈 못 잡으면 절대 못 이김** |

추가: 벽이 공격도 가능하면 (Sacred Fire, Scald 등) × 1.3 배.
시간 끌수록 우리만 손해니까.

G52 수정 후:
- 머테리얼: +2.4
- 돌파 실패: -2.0 × 1.3 = -2.6 (Ho-Oh Sacred Fire 공격 가능)
- 합계: -0.2 → tanh(-0.2) = **-0.20**
- AI: "못 이기는 중" → Iron Defense 같은 헛짓 안 함

---

## Day 3: Iterative Deepening — "어려운 수만 고민해라"

### 핵심 질문

값이 명확할 때까지 depth를 돌리게 하면?
지금은 고정이잖아. Stockfish도 어려운 수만 고민하잖아.

**고정 depth의 문제:**
- 쉬운 판 (3v1 확정승): depth-2면 충분 → depth-4~8은 시간 낭비
- 사이클 판 (회복 루프): depth-4로 부족 → 더 깊이 봐야 하는데 거기서 끝남

### 구현: Iterative Deepening

```python
for depth in [2, 4, 6, 8]:
    Nash 균형을 이 depth에서 풀기
    if |GV| > 0.9:            → 명확한 포지션, 즉시 종료
    if 최선수 안정 + GV 변동 < 0.1: → 수렴, 종료
    else:                      → 불명확, 더 깊이 탐색
```

### 결과

실제 벤치마크에서의 시간 분포:
- 쉬운 판: G11 = 4턴 **5.9초** (depth 2에서 바로 끝)
- 어려운 판: G1 = 11턴 **61.1초** (Dondozo 상대 → 사이클 감지 → 깊이 봄)
- 중간 판: G3 = 6턴 **18.7초**

> "애가 불리한 상황일수록 서칭을 더 하나보다.
> 긴 게임도 짧게 끝나는 경우가 있고 짧은 게임도 연산을 오래하는 경우가 있네."

정확히 Stockfish의 시간 관리와 같은 패턴.

---

## 최종 아키텍처

```
┌─────────────────────────────────────────────┐
│           스마트 선출 (Smart Selection)        │
│   20개 조합 × 5개 평가 컴포넌트 → 최적 3마리    │
│          + 리드 적합도 순서 정렬               │
└──────────────────┬──────────────────────────┘
                   │ 최적 3마리 + 리드
                   ▼
┌─────────────────────────────────────────────┐
│        Iterative Deepening 탐색              │
│    depth 2 → 4 → 6 → 8 (명확해질 때까지)      │
└──────────────────┬──────────────────────────┘
                   │ 각 depth에서:
                   ▼
┌─────────────────────────────────────────────┐
│             보상행렬 (Payoff Matrix)           │
│  (내 행동 × 상대 행동) 조합마다:               │
│    시뮬레이션 → 평가 → 행렬 채우기              │
└──────────────────┬──────────────────────────┘
                   │ N×M 보상행렬
                   ▼
┌─────────────────────────────────────────────┐
│        Nash 균형 솔버 (선형계획법)              │
│  혼합전략 = 각 행동의 확률 분포                 │
│  게임밸류 = 기대 결과 [-1, +1]                │
└──────────────────┬──────────────────────────┘
                   │ 행동 확률
                   ▼
┌─────────────────────────────────────────────┐
│        룰 기반 평가함수 (12개 컴포넌트)          │
│  머테리얼 · HP · 매치업 · 스윕 · 카운터          │
│  헤저드 · 상태이상 · 랭크업 · 필드 · 테라        │
│  돌파 가능성 · 방어 코어                       │
│       → tanh(가중합) → [-1, +1]              │
└─────────────────────────────────────────────┘
```

---

## 버전 히스토리

| 버전 | 승률 | 핵심 변경 |
|------|------|---------|
| 신경망 | ~50% | 포켓몬 메카닉 이해 불가 |
| MCTS | ~55% | 동시행동 게임에 잘못된 알고리즘 |
| Nash + depth-1 | ~70% | 1턴밖에 못 봄 |
| v1: 룰 평가 10개 | 83% | Stockfish 스타일 첫 버전 |
| v1 + 공격 프루닝 | ~60% | **프루닝이 Nash 균형 파괴** |
| v2: +돌파/코어 | 93% | 회복벽 감지 + 방어코어 인식 |
| v3: +스마트 선출 | 94% | 20조합 평가 + 리드 선택 |
| v3: +depth-4 | 96% | 4턴 사이클을 통째로 봄 |
| v3: +테라 버그 수정 | 94% | STAB 계산 정상화 + 가중치 조정 |
| v3: +Iterative Deepening | 측정중 | 유동 depth 2→8, 사이클 적응형 |

---

## 교훈

### 1. 포켓몬은 계산 게임이지 패턴 인식 게임이 아니다
신경망이 데미지 공식을 "학습"하는 건 바보짓이다. 공식이 있으면 계산하면 된다.
딥러닝이 만능이라는 환상을 깨야 한다.

### 2. 동시행동 게임에는 Nash 균형이 답이다
체스 AI의 전체 playbook (minimax, alpha-beta)이 적용 안 된다.
가위바위보를 minimax로 풀 수 없는 것과 같은 이유다.

### 3. 프루닝은 Nash 균형을 파괴한다
"나쁜 수"를 빼면 상대의 최적 전략이 바뀐다.
오직 **물리적으로 불가능한 행동**만 제거할 수 있다.
이것 때문에 이틀을 날렸다.

### 4. 평가 정확도 > 탐색 깊이
완벽한 depth-2 평가함수가 엉망인 depth-8보다 낫다.
**평가함수가 AI의 본체**이고, 탐색은 그걸 증폭하는 도구일 뿐.
교체도 하나의 행동이고, 평가만 정확하면 solver가 알아서 최선수를 찾는다.

### 5. 사이클은 수학적으로 강력하다
최적 엔진이 증명: 잘 짜인 회복 사이클은 진짜 뚫기 어렵다.
게임프리크가 매 세대 사이클을 너프하는 게 이유가 있다.

### 6. 어려운 수만 오래 고민해라 (Iterative Deepening)
쉬운 포지션에 depth-8을 쓰는 건 시간 낭비.
어려운 포지션에 depth-2만 쓰는 건 능력 부족.
Stockfish처럼 유동적으로.

### 7. 버그는 게임 트리에서 기하급수적으로 증폭된다
STAB 계산 하나가 1.5x vs 2.0x로 틀리면,
모든 리프 노드에서 테라 판단이 일관되게 틀린다.
한 줄의 버그가 전체 AI의 의사결정을 오염시킨다.

### 8. 이걸 왜 아무도 안 만들었나

필요한 지식이 너무 많다. 사실 지금 알고리즘도 짬뽕같아 보여도 엄청 독자적이다.

**체스가 쉬웠던 이유.** 완전정보 게임이라 서칭이 통한다. 거기다가 이미 말의 가치가
상댓값으로 연구되어 정해져 있다. 퀸=9, 룩=5, 비숍=3. 평가함수를 만들기 쉽다.

**바둑이 어려웠던 이유.** 역시 완전정보 게임이라 서칭은 통하지만,
"각 돌의 가치"를 AI에게 가르치는 것이 어려웠다.
그래서 신경망이 돌의 가치와 형세를 판단해야 했고, AlphaGo가 나왔다.

**LLM이 가능한 이유.** 목적함수가 명확하다. 일단 데이터 들이붓고
자연어라는 명확한 골을 향해 달려가면 된다. 손실함수 설계가 쉽다.

**포켓몬이 어려운 이유.** "뭐가 이득인지" AI한테 설명하는 것 자체가 어렵다.
포켓몬에서 이득이 뭔데? 기점 잡는 거? 사이클 잡는 거?
근데 그게 수학적으로 정확히 뭔데?
내 포켓몬 한 마리가 희생되더라도 에이스를 완벽한 상황에 강림시킨다면 이득이다.
그걸 손실함수 하나로 표현할 수 없다. 그래서 결국 신경망은 포기해야 했다.

거기다 불완전 정보 게임의 콜드 데이터를 어떻게 모으지?
상대가 뭘 들고 있는지도 모르는데?
그게 결국 리플레이 분석이랑 매크로 전략의 필요성으로 이어졌다.


---

## Day 4: 매크로 전략 — "왜 이 3마리를 골랐는지 모르는 AI"

### 문제 발견

94% 승률이라 좋아하고 있었는데, 인간이랑 붙어보니까 문제가 보였다.

AI가 팀 선출은 잘 하는데, **왜 그 3마리를 골랐는지 모른다.**

예를 들어 Chien-Pao(칼춤) + Flutter Mane(서포트) + Dondozo(탱커)를 골랐으면,
의도는 "날치머로 상대 깎고 → 파오리 칼춤 → 쓸어버리기" 세팅>스윕인데,
AI는 그냥 매 턴 Nash 균형만 풀어서 턴 단위 최적을 찾는다.

**탐색은 미시, 전략은 거시.** 이 둘이 연결이 안 되어있었다.

### 매크로 아키타입 3가지

`macro_search.py`에서 C(6,3) = 20개 조합마다 매크로 패턴을 탐지:

| 패턴 | 조건 | 게임플랜 |
|------|------|---------|
| **setup_sweep** | 적층기 보유 + 스윕 가능 에이스 | 서포트→에이스 착지→적층→스윕 |
| **break_clean** | 고화력 브레이커 + 고속 클리너 | 브레이커로 구멍→클리너 마무리 |
| **cycle** | 회복기 2+ 또는 피벗기 2+ | 헤저드→사이클→소모전 |

Stockfish 비유: 평가함수가 전략을 유도한다.
"에이스를 살려야 한다"는 걸 평가함수가 알면, 탐색이 알아서 에이스를 아끼는 수를 찾는다.

### 서브골 분해

처음엔 매크로별로 가중치만 바꿨는데, 그것만으론 부족했다.
게임 진행에 따라 **단계(phase)**가 바뀌어야 한다.

setup_sweep이면:
1. **support** — 서포터로 상대 깎기. 에이스 온존.
2. **land** — 에이스 안전하게 착지.
3. **setup** — 적층기 사용. 랭크업 가중치 폭발적 증가.
4. **sweep** — 쓸어버리기. 스윕 위협 가중치 최대.

break_clean이면:
1. **break** — 브레이커가 상대 벽 뚫기. 돌파 가능성 가중치 1.8.
2. **transition** — 브레이커 소모 후 클리너로 전환.
3. **clean** — 약해진 상대 쓸어버리기.

12개 가중치 튜플이 매크로×단계별로 다르다.
`_detect_macro_phase()`가 현재 상태에서 "지금 어떤 단계인지" 판단하고,
그에 맞는 가중치로 평가.

---

## Day 4: 첫 인간 대전 — "얘 잘하는데?"

### Showdown 라이브 대전

로컬 Showdown 서버 띄우고, MacroNash 봇으로 접속.
상대는 나(개발자). BSS Reg I 포맷.

**1판: AI 승리 — Flutter Mane 스윕**
Moonblast 5연타로 상대 팀 전멸. 구안경 날치머가 그냥 미쳤다.

**2판: AI 승리 — Dragonite setup_sweep**
용의춤 → 날개쉬기 → 용의춤 → 신속으로 스윕. 매크로 그대로 실행됨.
9턴, 교과서적인 세팅스윕.

**3판: AI 패배 — Dragonite가 1턴에 테라 낭비**
세팅스윕 매크로는 맞았는데 테라를 첫 턴에 써버림.
"중간까지 세트업 잘 됐음" — 전략은 맞았고 실행에서 실수.

**4판: AI 패배 — Dondozo 방어 스팸**
Chien-Pao 세팅스윕, 서포트 단계까지 완벽. 그런데 엔드게임에서
Dondozo가 방어(Protect)를 **7턴 연속** 사용. 상대가 뚫을 방법이 없어서
PP 다 쓸 때까지 기다림. 근데 그 사이에 역전당함.

### 방어 스팸 — depth-1의 한계

왜 Protect를 무한으로 쓰나?

depth-1 Nash에서 매 턴 독립적으로 판단하니까:
- "이 턴에 방어 → 상대 공격 헛침 → 포지션 동일 → GV 유지"
- "이 턴에 공격 → 반격 맞을 수 있음 → GV 하락 가능"
- → 매번 방어가 최적

**연속 방어는 성공률이 1/3으로 떨어진다**는 걸 depth-1은 모른다.
실제 게임에서 2연속 방어는 거의 안 통하는데, AI는 매번 "이번 턴만" 본다.

### 프루닝으로 해결

`prune_obvious()`에 "연속 방어 금지" 추가:
- `protect_count >= 1`이면 방어류 기술 전부 후보에서 제거
- 방어, 탐지, 니들가드, 킹실드, 옵스트럭트, 실크트랩, 버닝벌워크 전부 포함

**5판: AI 승리 — Urshifu break_clean**
브레이커>클리너 매크로 완벽 실행.
턴 1 인파이트 100% → 브레이커가 구멍 뚫고 → 클리너 미라이돈이 마무리.
7턴 클린 게임. 방어 스팸 없음.

근데 여기서 재미있는 일이 생겼다.

### Nash 균형의 위력 — "인파이트를 어떻게 읽었어?"

상대 망나뇽(드래곤/비행) 대면에서 AI가 인파이트(격투)를 선택.
상성으로만 보면 격투→비행은 반감이라 아이스스피너(얼음, 4배)가 맞다.

근데 Nash 균형은:
- 상대가 테라스탈(타입 변경)할 가능성을 포함한 **전체 행동 공간**에서 최적
- 망나뇽이 강철 테라로 바꾸면? 아이스스피너 반감, 인파이트 2배
- 테라 안 하면? 아이스스피너가 낫지만 확률적으로 인파이트가 안정적

**"읽은" 게 아니라 모든 가능성의 균형점.** 이게 Nash의 힘이다.

### Showdown에서 protect_count가 0인 문제

방어 프루닝을 넣었는데 **라이브 대전에서 다시 방어 스팸** 발생.

원인: poke-env 라이브러리가 `protect_count`를 파싱 안 함. 항상 0.
내부 시뮬레이터에서는 잘 되는데 Showdown 브릿지에서 값이 안 넘어옴.

**수정: NashPlayer 내부에서 직접 추적.**
`_used_protect_last` 딕셔너리로 포켓몬별 지난 턴 방어 사용 여부를 기록.
choose_move() 시작 시 protect_count를 패치.

---

## Day 4: 전적 정리

인간 vs AI, BSS Reg I:

| # | 결과 | AI 팀 | 매크로 | 비고 |
|---|------|-------|--------|------|
| 1 | **승** | Flutter Mane 외 | break_clean | 날치머 Moonblast 스윕 |
| 2 | **승** | Dragonite 외 | setup_sweep | 용춤→날개쉬기→용춤→신속 |
| 3 | **패** | Dragonite 외 | setup_sweep | 1턴 테라 낭비 |
| 4 | **패** | Chien-Pao 외 | setup_sweep | 방어 스팸 (수정 전) |
| 5 | **승** | Urshifu 외 | break_clean | 인파이트 7턴 클린 |
| 6 | **승** | Urshifu 외 | break_clean | 1턴 테라+아쿠아제트 |
| 7 | **패** | Flutter Mane 외 | break_clean | 날치머 3턴에 사망 |
| 8 | **패** | 돈도조 외 | break_clean | 방어 스팸 재발 (poke-env 버그) |
| 9 | **승** | Flutter Mane 외 | setup_sweep | 날치머 Moonblast 파괴 |
| 10 | **승** | Raging Bolt 외 | setup_sweep | 교체 타이밍 완벽, Thunderclap 마무리 |

**6승 4패.** depth-1~2짜리 엔진이 인간(개발자)을 상대로 6:4.

체감상 패배한 판도 중반까지 유리한 경우가 많았다.
매크로 전략이 맞는데 실행 디테일(테라 타이밍, 스락 체크)에서 빈틈이 생김.

---

## 남은 과제

아직 모자란 점 많다고 생각한다. 고레이팅 유저랑 붙을 정도는 아니다.

그리고 방어에 왜 연속 사용 패널티가 달려 있는지 알 거 같다.
AI는 연속 방어를 굉장히 유효한 수로 본다.
매 턴 독립적으로 판단하면 "이번 턴 방어 = 상대 공격 무효화 = 이득"이니까.
게임프리크가 연속 방어 성공률을 1/3으로 떨어뜨린 건 정확히 이걸 막기 위한 거였다.

### 근본적 한계: depth
- depth-1~2라서 2수 뒤 상황을 못 봄
- 자마젠타 철벽 기점 허용, 스피드 관계 오판 등
- 평가함수가 좋으니까 1수만 봐도 꽤 잘하지만, 기점 허용은 구조적 문제

### 불완전 정보
- 상대 기술셋을 모름 → Smogon 통계 기반 추론
- 세트 추론기(set_inferencer)가 있긴 한데 아직 초보 수준
- "상대가 뭘 들고 있는지"에 따라 최적 행동이 완전히 바뀜

### 테라 관리
- 서브골 보너스로 "에이스한테 테라 아끼기"를 유도하지만
- 가끔 1턴에 서포터한테 테라 써버리는 경우 아직 있음
- 테라 타이밍 = 포켓몬 배틀 최고 난이도 의사결정 중 하나

---

## 버전 히스토리 (업데이트)

| 버전 | 승률 | 핵심 변경 |
|------|------|---------|
| 신경망 | ~50% | 포켓몬 메카닉 이해 불가 |
| MCTS | ~55% | 동시행동 게임에 잘못된 알고리즘 |
| Nash + depth-1 | ~70% | 1턴밖에 못 봄 |
| v1: 룰 평가 10개 | 83% | Stockfish 스타일 첫 버전 |
| v1 + 공격 프루닝 | ~60% | **프루닝이 Nash 균형 파괴** |
| v2: +돌파/코어 | 93% | 회복벽 감지 + 방어코어 인식 |
| v3: +스마트 선출 | 94% | 20조합 평가 + 리드 선택 |
| v3: +depth-4 | 96% | 4턴 사이클을 통째로 봄 |
| v3: +테라 버그 수정 | 94% | STAB 계산 정상화 + 가중치 조정 |
| v3: +Iterative Deepening | 94%+ | 유동 depth 2→8, 사이클 적응형 |
| **v0.1: 매크로 전략** | **vs 인간 6:4** | 매크로 탐지 + 서브골 평가 + Showdown 실전 |
